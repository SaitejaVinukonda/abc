{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMijtmJQilYDdYVewiG0z6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaitejaVinukonda/abc/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "sidDGb6K28tn",
        "outputId": "bf120537-7179-409d-f6b5-8f726ea23fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading omw_1.4: Package 'omw_1.4' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'word_lemmatizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3c3092d15754>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lemma for {} is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_lemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'word_lemmatizer' is not defined"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw_1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer=WordNetLemmatizer()\n",
        "text=\"studies studying flies fly\"\n",
        "tokenization=nltk.word_tokenize(text)\n",
        "for w in tokenization:\n",
        "  print(\"lemma for {} is {}\".format(w,word_lemmatizer.lemmatize(w)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4OqhDsUWfx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "train = [\n",
        " ('I love this sandwich.', 'pos'),\n",
        " ('This is an amazing place!', 'pos'),\n",
        " ('I feel very good about these beers.', 'pos'),\n",
        " ('This is my best work.', 'pos'),\n",
        " (\"What an awesome view\", 'pos'),\n",
        " ('I do not like this restaurant', 'neg'),\n",
        " ('I am tired of this stuff.', 'neg'),\n",
        " (\"I can't deal with this\", 'neg'),\n",
        " ('He is my sworn enemy!', 'neg'),\n",
        " ('My boss is horrible.', 'neg')\n",
        "]\n",
        "test = [\n",
        " ('The beer was good.', 'pos'),\n",
        " ('I do not enjoy my job', 'neg'),\n",
        " (\"I ain't feeling dandy today.\", 'neg'),\n",
        " (\"I feel amazing!\", 'pos'),\n",
        " ('Gary is a friend of mine.', 'pos'),\n",
        " (\"I can't believe I'm doing this.\", 'neg')\n",
        "]\n",
        "cl = NaiveBayesClassifier(train)\n",
        "cl.classify(\"Their burgers are amazing\") # \"pos\"\n",
        "cl.classify(\"I don't like their pizza.\") # \"neg\"\n",
        "from textblob import TextBlob\n",
        "blob = TextBlob(\"The beer was amazing. \" \"But the hangover was horrible. My boss was not happy.\",classifier=cl)\n",
        "print(blob)\n",
        "print(blob.classify())\n",
        "for sentence in blob.sentences:\n",
        " print(sentence)\n",
        " print(sentence.classify())\n",
        "# Compute accuracy\n",
        "print(\"Accuracy: {0}\".format(cl.accuracy(test)))\n",
        "cl.show_informative_features(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s3WqEVbWgpF",
        "outputId": "92eb3ccb-0daa-4458-b158-faed37a03501"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The beer was amazing. But the hangover was horrible. My boss was not happy.\n",
            "neg\n",
            "The beer was amazing.\n",
            "pos\n",
            "But the hangover was horrible.\n",
            "neg\n",
            "My boss was not happy.\n",
            "neg\n",
            "Accuracy: 0.8333333333333334\n",
            "Most Informative Features\n",
            "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
            "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
            "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
            "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
            "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw_1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer # Corrected import statement\n",
        "wordnet_lemmatizer=WordNetLemmatizer()\n",
        "text=\"studies studying flies fly\"\n",
        "tokenization=nltk.word_tokenize(text)\n",
        "for w in tokenization:\n",
        "  print(\"lemma for {} is {}\".format(w,wordnet_lemmatizer.lemmatize(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjU2dhvF44Mm",
        "outputId": "6fab43f0-8279-4bed-c012-75da37f31979"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading omw_1.4: Package 'omw_1.4' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma for studies is study\n",
            "lemma for studying is studying\n",
            "lemma for flies is fly\n",
            "lemma for fly is fly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw_1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "text=\"studies studying cries cry\"\n",
        "tokenization=nltk.word_tokenize(text)\n",
        "for w in tokenization:\n",
        "  print(\"stemming for {} is {}\".format(w,porter_stemmer.stem(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685mtVKE9bGS",
        "outputId": "772e9b74-ac42-49b6-814d-c43721d5b9de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stemming for studies is studi\n",
            "stemming for studying is studi\n",
            "stemming for cries is cri\n",
            "stemming for cry is cri\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading omw_1.4: Package 'omw_1.4' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}